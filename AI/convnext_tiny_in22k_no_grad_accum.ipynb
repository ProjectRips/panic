{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training & result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkaggle import *\n",
    "import os\n",
    "import timm\n",
    "from fastai.vision.all import *\n",
    "import gc\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 'data'\n",
    "\n",
    "path = setup_comp(comp, install='\"fastcore>=1.4.5\" \"fastai>=2.7.1\" \"timm>=0.6.2.dev0\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('data/test'),Path('data/train')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train\n"
     ]
    }
   ],
   "source": [
    "trn_path = path/'train'\n",
    "files = get_image_files(trn_path)\n",
    "\n",
    "print(trn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'convnext_tiny_in22k': {\n",
    "        (Resize(480, method='squish'), 224),\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=15):\n",
    "    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.25, item_tfms=item,\n",
    "        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64)\n",
    "    learn = vision_learner(dls, arch, metrics=[error_rate]).to_fp16()\n",
    "    lr_valley, lr_slide = learn.lr_find(suggest_funcs=(valley, slide))\n",
    "    \n",
    "    return lr_valley, lr_slide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- convnext_tiny_in22k\n",
      "224\n",
      "Resize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tta_res = []\n",
    "\n",
    "for arch,details in models.items():\n",
    "    for item,size in details:\n",
    "        print('---',arch)\n",
    "        print(size)\n",
    "        print(item.name)\n",
    "        \n",
    "        lr_valley, lr_slide = find_lr(arch, size, item=item, finetune=True, accum=4)\n",
    "    \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(recorder, skip_start=5, with_valid=True):\n",
    "        plt.plot(list(range(skip_start, len(recorder.values))), recorder.values[skip_start:], label='train')\n",
    "        if with_valid:\n",
    "            idx = (np.array(recorder.iters)<skip_start).sum()\n",
    "            valid_col = recorder.metric_names.index('valid_accuracy') - 1 \n",
    "            plt.plot(recorder.iters[idx:], L(recorder.values[idx:]).itemgot(valid_col), label='valid')\n",
    "            plt.figure(1)\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=15):\n",
    "    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.25, item_tfms=item,\n",
    "                                       batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n",
    "\n",
    "    cbs = [GradientAccumulation(64) if accum else [], EarlyStoppingCallback(min_delta=1e-4, patience=10), SaveModelCallback(monitor=\"valid_loss\")]\n",
    "    learn = vision_learner(dls, arch, metrics=[accuracy, error_rate], cbs=cbs).to_fp16()\n",
    "    learn.recorder.train_metrics = True\n",
    "    tst_files = get_image_files(path/'test').sorted()\n",
    "    if finetune:\n",
    "        learn.fine_tune(epochs, 0.01)\n",
    "        learn.recorder.plot_loss()\n",
    "        learn.recorder.plot_values()\n",
    "        learn.tta(dl=dls.test_dl(tst_files))\n",
    "    else:\n",
    "        learn.unfreeze()\n",
    "        \n",
    "        learn.fit_one_cycle(epochs, 0.01)\n",
    "        learn.recorder.plot_loss()\n",
    "        learn.recorder.plot_values()\n",
    "\n",
    "    return learn, dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- convnext_tiny_in22k\n",
      "224\n",
      "Resize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.156610</td>\n",
       "      <td>0.603898</td>\n",
       "      <td>0.396102</td>\n",
       "      <td>0.719511</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.225962</td>\n",
       "      <td>15:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.7195112109184265.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/40 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_error_rate</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='97' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/97 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 4.00 GiB total capacity; 3.30 GiB already allocated; 0 bytes free; 3.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\kuliah\\semester 7\\deep-learning-paddy-disease-classification\\convnext_tiny_in22k_no_grad_accum.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(item\u001b[39m.\u001b[39mname)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m learn, dls \u001b[39m=\u001b[39m train(arch, size, item\u001b[39m=\u001b[39;49mitem, finetune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accum\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m learn\u001b[39m.\u001b[39msave(arch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m learn\u001b[39m.\u001b[39mexport(\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39march\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\kuliah\\semester 7\\deep-learning-paddy-disease-classification\\convnext_tiny_in22k_no_grad_accum.ipynb Cell 14\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(arch, size, item, accum, finetune, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m tst_files \u001b[39m=\u001b[39m get_image_files(path\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msorted()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m finetune:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     learn\u001b[39m.\u001b[39;49mfine_tune(epochs, \u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     learn\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mplot_loss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/kuliah/semester%207/deep-learning-paddy-disease-classification/convnext_tiny_in22k_no_grad_accum.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     learn\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mplot_values()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\callback\\schedule.py:168\u001b[0m, in \u001b[0;36mfine_tune\u001b[1;34m(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m base_lr \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munfreeze()\n\u001b[1;32m--> 168\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_one_cycle(epochs, \u001b[39mslice\u001b[39;49m(base_lr\u001b[39m/\u001b[39;49mlr_mult, base_lr), pct_start\u001b[39m=\u001b[39;49mpct_start, div\u001b[39m=\u001b[39;49mdiv, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\callback\\schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    116\u001b[0m lr_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([h[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mhypers])\n\u001b[0;32m    117\u001b[0m scheds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[39m/\u001b[39mdiv, lr_max, lr_max\u001b[39m/\u001b[39mdiv_final),\n\u001b[0;32m    118\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mmom\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, \u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoms \u001b[39mif\u001b[39;00m moms \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m moms))}\n\u001b[1;32m--> 119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mParamScheduler(scheds)\u001b[39m+\u001b[39;49mL(cbs), reset_opt\u001b[39m=\u001b[39;49mreset_opt, wd\u001b[39m=\u001b[39;49mwd, start_epoch\u001b[39m=\u001b[39;49mstart_epoch)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[1;32m--> 256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[0;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_train()\n\u001b[0;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch_train\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelTrainException)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m    225\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_device(b)\n\u001b[0;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b)\n\u001b[1;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\learner.py:205\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_one_batch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxb)\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_pred\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb):\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fastai\\vision\\learner.py:177\u001b[0m, in \u001b[0;36mTimmBody.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[1;32m--> 177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward_features(x) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_pool \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\timm\\models\\convnext.py:353\u001b[0m, in \u001b[0;36mConvNeXt.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_features\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    352\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstem(x)\n\u001b[1;32m--> 353\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstages(x)\n\u001b[0;32m    354\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_pre(x)\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\timm\\models\\convnext.py:210\u001b[0m, in \u001b[0;36mConvNeXtStage.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    208\u001b[0m     x \u001b[39m=\u001b[39m checkpoint_seq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks, x)\n\u001b[0;32m    209\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[0;32m    211\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\timm\\models\\convnext.py:148\u001b[0m, in \u001b[0;36mConvNeXtBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    146\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    147\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[1;32m--> 148\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(x)\n\u001b[0;32m    149\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\timm\\models\\layers\\mlp.py:27\u001b[0m, in \u001b[0;36mMlp.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 27\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[0;32m     28\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n\u001b[0;32m     29\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop1(x)\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ricky\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 4.00 GiB total capacity; 3.30 GiB already allocated; 0 bytes free; 3.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for arch,details in models.items():\n",
    "    for item,size in details:\n",
    "        print('---',arch)\n",
    "        print(size)\n",
    "        print(item.name)\n",
    "        \n",
    "        learn, dls = train(arch, size, item=item, finetune=True, accum=1, epochs=40)\n",
    "        learn.save(arch+\"_no_grad_accum\")\n",
    "        learn.export(\"models/\"+arch+\"_no_grad_accum.pkl\")\n",
    "\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'convnext_tiny_in22k': {\n",
    "        (Resize(480, method='squish'), 224),\n",
    "    },\n",
    "}\n",
    "\n",
    "def train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True):\n",
    "    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.25, item_tfms=item,\n",
    "        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=32//accum)\n",
    "    cbs = GradientAccumulation(64) if accum else []\n",
    "    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n",
    "\n",
    "    return learn, dls\n",
    "\n",
    "for arch,details in models.items():\n",
    "    for item,size in details:\n",
    "        print('---',arch)\n",
    "        print(size)\n",
    "        print(item.name)\n",
    "        \n",
    "        learn, dls = train(arch, size, item=item, finetune=True, accum=4)\n",
    "    \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpret = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   bacterial_leaf_blight       0.94      0.97      0.96        66\n",
      "   bacterial_leaf_streak       0.98      0.98      0.98        59\n",
      "bacterial_panicle_blight       1.00      1.00      1.00        48\n",
      "                   blast       0.98      0.99      0.99       312\n",
      "              brown_spot       0.97      0.99      0.98       153\n",
      "              dead_heart       1.00      1.00      1.00       218\n",
      "            downy_mildew       0.97      0.96      0.97       101\n",
      "                   hispa       0.96      0.96      0.96       233\n",
      "                  normal       0.98      0.97      0.97       286\n",
      "                  tungro       0.99      0.97      0.98       188\n",
      "\n",
      "                accuracy                           0.98      1664\n",
      "               macro avg       0.98      0.98      0.98      1664\n",
      "            weighted avg       0.98      0.98      0.98      1664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('normal', 'hispa', 8),\n",
       " ('hispa', 'normal', 4),\n",
       " ('hispa', 'blast', 3),\n",
       " ('blast', 'brown_spot', 2),\n",
       " ('tungro', 'downy_mildew', 2),\n",
       " ('bacterial_leaf_blight', 'blast', 1),\n",
       " ('bacterial_leaf_blight', 'normal', 1),\n",
       " ('bacterial_leaf_streak', 'bacterial_leaf_blight', 1),\n",
       " ('blast', 'normal', 1),\n",
       " ('brown_spot', 'bacterial_leaf_streak', 1),\n",
       " ('downy_mildew', 'bacterial_leaf_blight', 1),\n",
       " ('downy_mildew', 'blast', 1),\n",
       " ('downy_mildew', 'brown_spot', 1),\n",
       " ('downy_mildew', 'hispa', 1),\n",
       " ('hispa', 'bacterial_leaf_blight', 1),\n",
       " ('hispa', 'downy_mildew', 1),\n",
       " ('normal', 'brown_spot', 1),\n",
       " ('normal', 'tungro', 1),\n",
       " ('tungro', 'bacterial_leaf_blight', 1),\n",
       " ('tungro', 'blast', 1),\n",
       " ('tungro', 'normal', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'tungro']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1 (tags/v3.8.1:1b293b6, Dec 18 2019, 23:11:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8e103f1427e845b325d32d1d1b7a680a975242c9df6a2c0532359a1c20fb4b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
